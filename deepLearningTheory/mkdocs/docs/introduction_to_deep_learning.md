# Introduction to deep learning

## What is neuronal networks?

<img src="../img/relu.png" width="400" />

So if you are familiar with linear regression you might say, well let's put a straight line to these data so and we get a straight line like that. But to be Pathans you might say well we know that prices can never be negative. 

So instead of the straight line fit which eventually will become negative, let's bend the curve here so it just ends up zero here. So this thick blue line ends up being your function for predicting the price of the house as a function of this size. Whereas zero here and then there's a straight line fit to the right.


Rectified linear units. So RELU.

## Supervised Learning with Neural Networks

<img src="../img/supervised_learning.png" width="400" />

----

<img src="../img/supervised_learning_examples.png" width="400" />

----
### Structured data / Unstructured data

<img src="../img/structured_unstructured_data.png" width="400" />

Would structured or unstructured data have features such as pixel values or individual words?

Answer: Unstructured data

## Why is Deep Learning taking off?

Scale of Data and performance of the algorithm: <img src="../img/scale_drives_deep_learning_progress.png" width="400" />

<img src="../img/sigmoid_to_relu.png" width="400" />

* Data scale (early days of NN)
* Computation power (early days of NN)
* Algorithmics innovations make it faster: Switching to the sigmoid function to the rayleigh function has made an algorithm called gradient descent work much faster and so this is an example of maybe relatively simple algorithm in Bayesian but ultimately the impact of this algorithmic innovation was it really hope computation so the regimen quite a lot of examples like this of where we change the algorithm because it allows that code to run much faster and this allows us to train bigger neural networks.

<img src="../img/test.png" width="400" />

----


What will the variable m denote in this course?

* Number of hidden layers
* Number of training examples; Correct 
* The expected output
* Slope

   Interview Geoffrey Hinton

